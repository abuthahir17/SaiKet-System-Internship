# -*- coding: utf-8 -*-
"""Task 4: Churn Prediction Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nrsspD_T2StR6mILobkAqb5wkhlZOdQm

# **Task 4: Churn Prediction Model**

# 1. Load and Clean the Dataset


```
1.1 Import Libraries
1.2 Data From GitHub
1.3 Check the missing values
1.4 Convert TotalCharges to Numeric
1.5 Fill the missing value with median
1.6 Also Check the " " value
1.7 Convert types
```
"""

# 1.1 Import Libraries
import pandas as pd
import numpy as np

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier

import matplotlib.pyplot as plt
import seaborn as sns

# 1.2 Data From GitHub

# GitHub raw URL
url = 'https://raw.githubusercontent.com/abuthahir17/Dataset/main/Telco_Customer_Churn_Dataset.csv'

# Read CSV file
data = pd.read_csv(url)

print("Dataset Loaded Successfully!")

# 1.3 Check the missing values
data.replace(" ", None, inplace=True)
print("Missing Value: \n", data.isnull().sum())

# 1.4 Convert TotalCharges to Numeric
data["TotalCharges"] = pd.to_numeric(data["TotalCharges"], errors="coerce")

# 1.5 Fill the missing value with median
data["TotalCharges"] = data["TotalCharges"].fillna(data["TotalCharges"].median())

# 1.6 Also Check the " " value
data.replace(" ", None, inplace=True)
print("Missing Value after Cleaning: \n", data.isnull().sum())

# 1.7 Convert types
data["Churn"] = data["Churn"].map({"Yes":1, "No":0})

"""# 2. Encoding Categorical Variables



```
2.1 Identify Numerical and Categorical Columns
2.2 Before Encoding
2.3 During Encoding
2.4 After Encoding
```


"""

# 2.1 Identify numerical columns
numerical_cols = data.select_dtypes(include=['int64', 'float64']).columns
print("Total number of Numerical Columns:", len(numerical_cols))
print("All Numerical Columns:" ,list(numerical_cols), "\n")

# 2.1 Identify categorical columns
categorical_cols = data.select_dtypes(include=['object']).columns
print("Total number of Categorical Columns:", len(categorical_cols))
print("All Categorical Columns:" , list(categorical_cols))

# 2.2 Before Encoding

print("Before encoding:\n", data.head())
print("Shape before encoding:", data.shape)

# 2.3 During Encoding

from sklearn.preprocessing import LabelEncoder

# Binary columns (2 unique values)
binary_cols = [col for col in categorical_cols if data[col].nunique() == 2]
print("Binary Columns (LabelEncode):", binary_cols, "\n")

# Multi-category columns (>2 unique values)
multi_cat_cols = [col for col in categorical_cols if data[col].nunique() > 2 and col not in binary_cols]
print("Multi-category Columns (One-hot Encode):", multi_cat_cols, "\n")

label_encoder = LabelEncoder()

# Binary
for col in binary_cols:
    data[col] = label_encoder.fit_transform(data[col])

# Multi-Category (One-Hot Encoding)
data = pd.get_dummies(data, columns=multi_cat_cols, drop_first=True)

print("Categorical Encoding Completed.")

# 2.4 After Encoding

print("After encoding:\n", data.head())
print("New Shape After Encoding:", data.shape)

"""# 3. Dataset Splitting (Train/Test)


```
3.1 Fix the target variable
3.2 Split the Dataset
```


"""

#3.1 Fix the target variable
from sklearn.model_selection import train_test_split

# Target variable
X = data.drop("Churn", axis=1)
y = data["Churn"]

# 3.2 Split the dataset into 2 set (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print("Training set shape:", X_train.shape)
print("Testing set shape:", X_test.shape)

"""# 4. Standardize Numerical Features"""

scaler = StandardScaler()
num_cols = ['tenure', 'MonthlyCharges', 'TotalCharges']

# scale only if columns exist in X (safety)
num_cols = [c for c in num_cols if c in X_train.columns]

X_train[num_cols] = scaler.fit_transform(X_train[num_cols])
X_test[num_cols] = scaler.transform(X_test[num_cols])

"""# 5. Fix class imbalance on training set using SMOTE"""

from imblearn.over_sampling import SMOTE

# Synthetic Minority Oversampling Technique (SMOTE) -> To fix class imbalance in your churn dataset.

smote = SMOTE(random_state=42)
X_train_sm, y_train_sm = smote.fit_resample(X_train, y_train)
print("After SMOTE ->", X_train_sm.shape, y_train_sm.sum(), "positive samples")

"""# 6. Model Training



```
6.1 Logistic Regression
6.2 Decision Tree
6.3 Random Forest
```


"""

# 6.1 Logistic Regression

log = LogisticRegression(max_iter=1000, random_state=42)
log.fit(X_train_sm, y_train_sm)
y_pred_log = log.predict(X_test)

print("Logistic Regression Results:")
print(classification_report(y_test, y_pred_log))

# 6.2 Decision Tree

dt = DecisionTreeClassifier(random_state=42)
dt.fit(X_train_sm, y_train_sm)
y_pred_tree = dt.predict(X_test)

print("Decision Tree Results:")
print(classification_report(y_test, y_pred_tree))

# 6.3 Random Forest

rf = RandomForestClassifier(n_estimators=200, random_state=42)
rf.fit(X_train_sm, y_train_sm)
y_pred_rf = rf.predict(X_test)

print("Random Forest Results:")
print(classification_report(y_test, y_pred_rf))

"""# 7. Hyperparameter tuning for RandomForest (GridSearchCV)"""

# Hyperparameter Tuning (Decision Tree Example)
from sklearn.model_selection import GridSearchCV

param_grid = {
    'n_estimators': [100, 200],
    'max_depth': [5, 10, None],
    'min_samples_split': [2, 5]
}

grid = GridSearchCV(
    RandomForestClassifier(random_state=42),
    param_grid,
    scoring='f1',
    cv=3,
    n_jobs=-1,
    verbose=1
)

grid.fit(X_train_sm, y_train_sm)
best_rf = grid.best_estimator_
print("\nGridSearch best params:", grid.best_params_)

"""# 8. Tuned Random Forest Evaluation


```
8.1 Classification Report of Tuned Random Forest
8.2 Confusion Matrix of Tuned Random Forest
8.3 ROC Curve and AUC Score
```


"""

# 8.1 Classification Report of Tuned Random Forest
y_pred_best = best_rf.predict(X_test)
print("\nTuned Random Forest:\n", classification_report(y_test, y_pred_best))

# 8.2 Confusion Matrix of Tuned Random Forest
cm = confusion_matrix(y_test, y_pred_best)
plt.figure(figsize=(5,4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title("Confusion Matrix - Tuned RF")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

# 8.3 ROC Curve and AUC Score
from sklearn.metrics import roc_curve, roc_auc_score

y_prob = best_rf.predict_proba(X_test)[:, 1]
fpr, tpr, thresholds = roc_curve(y_test, y_prob)
auc = roc_auc_score(y_test, y_prob)
plt.figure(figsize=(6,4))
plt.plot(fpr, tpr, label=f"AUC = {auc:.3f}")
plt.plot([0,1],[0,1],'k--')
plt.title("ROC Curve - Tuned RF")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.legend()
plt.show()

"""# 9. Feature Importance"""

# Feature Importance (Random Forest)

importances = pd.Series(best_rf.feature_importances_, index=X.columns)
top_imp = importances.sort_values(ascending=False).head(15)
plt.figure(figsize=(10,8))
top_imp.plot(kind='barh')
plt.gca().invert_yaxis()
plt.title("Top 15 Feature Importances (Tuned RF)")
plt.show()

"""# 10. Final comparison table"""

# 10. Final comparison

def evaluate(name, y_true, y_pred):
    print(f"\n{name}")
    print("Accuracy :", accuracy_score(y_true, y_pred))
    print("Precision:", precision_score(y_true, y_pred, zero_division=0))
    print("Recall   :", recall_score(y_true, y_pred, zero_division=0))
    print("F1 Score :", f1_score(y_true, y_pred, zero_division=0))

evaluate("Logistic Regression", y_test, y_pred_log)
evaluate("Decision Tree", y_test, y_pred_tree)
evaluate("Random Forest (baseline)", y_test, y_pred_rf)
evaluate("Random Forest (tuned)", y_test, y_pred_best)