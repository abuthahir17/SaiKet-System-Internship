# -*- coding: utf-8 -*-
"""Task 1 - Data Preparation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ao-ATum2rRGgxj1XyQ1ZrwITsQ5wsycW

# 1. Loading the Dataset

```
1. Data From GitHub
2. Display First 5 Rows
3. Shape of the Dataset
```
"""

import pandas as pd

# GitHub raw URL
url = 'https://raw.githubusercontent.com/abuthahir17/Dataset/main/Telco_Customer_Churn_Dataset.csv'

# Read CSV file
data = pd.read_csv(url)

print("Dataset Loaded Successfully!")

# Display First 5 rows
print("First Five Rows in the Dataset: \n")
data.head()

print("Shape of dataset:", data.shape)

"""# 2. Initial Data Exploration


```
1. Dataset Information
2. Statistical Summary of the Dataset
3. Data type of the Dataset
4. Number of Missing Values (Count)
```


"""

print("\nDataset Info:\n")
print(data.info())

print("\nStatistical Summary:\n")
print(data.describe(include='all'))

# Print Column data types
print("Column Data Types:\n", data.dtypes, "\n")

print("\nNumber of the missing values in each column:\n")
print(data.isnull().sum())

"""# 3. Handling Missing Values


```
1. Check also " " value (Null)
2. TotalCharges -> Numeric (Convert)
3. Fill with Median
4. Recheck Null values
```


"""

# Also Check the " " value

data.replace(" ", None, inplace=True)
print("Missing Value: \n", data.isnull().sum())

# Convert TotalCharges to Numeric
data["TotalCharges"] = pd.to_numeric(data["TotalCharges"], errors="coerce")

# Fill the missing value with median
data["TotalCharges"] = data["TotalCharges"].fillna(data["TotalCharges"].median())

# Also Check the " " value
data.replace(" ", None, inplace=True)
print("Missing Value after Cleaning: \n", data.isnull().sum())

"""# 4. Encoding Categorical Variables



```
1. Identify Numerical and Categorical Columns
2. Before Encoding
3. During Encoding
4. After Encoding
```


"""

# Identify numerical columns
numerical_cols = data.select_dtypes(include=['int64', 'float64']).columns
print("Total number of Numerical Columns:", len(numerical_cols))
print("All Numerical Columns:" ,list(numerical_cols), "\n")

# Identify categorical columns
categorical_cols = data.select_dtypes(include=['object']).columns
print("Total number of Categorical Columns:", len(categorical_cols))
print("All Categorical Columns:" , list(categorical_cols))

print("Before encoding:\n", data.head())

print("Shape before encoding:", data.shape)

from sklearn.preprocessing import LabelEncoder

# Binary columns (2 unique values)
binary_cols = [col for col in categorical_cols if data[col].nunique() == 2]
print("Binary Columns (LabelEncode):", binary_cols, "\n")

# Multi-category columns (>2 unique values)
multi_cat_cols = [col for col in categorical_cols if data[col].nunique() > 2 and col not in binary_cols]
print("Multi-category Columns (One-hot Encode):", multi_cat_cols, "\n")

label_encoder = LabelEncoder()

# Binary
for col in binary_cols:
    data[col] = label_encoder.fit_transform(data[col])

# Multi-Category (One-Hot Encoding)
data = pd.get_dummies(data, columns=multi_cat_cols, drop_first=True)

print("Categorical Encoding Completed.")

print("After encoding:\n", data.head())
print("New Shape After Encoding:", data.shape)

"""# 5. Dataset Splitting (Train/Test)


```
1. Fix the target variable
2. Split the Dataset
```


"""

from sklearn.model_selection import train_test_split

# Target variable
y = data["Churn"]
X = data.drop("Churn", axis=1)

# Split the dataset into 2 set (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print("Training set shape:", X_train.shape)
print("Testing set shape:", X_test.shape)

